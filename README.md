# BeyondChats Blog Automation Project

This project automates blog content enhancement using web scraping, Google search, and LLM-based rewriting.  
It is divided into **three phases**: backend scraping & APIs, automated content enhancement, and a React-based frontend UI.

---

## ğŸ§© Project Overview

### Phase 1 â€“ Backend & Scraping

- Scrapes the **5 oldest articles** from the BeyondChats blog.
- Stores articles in a database.
- Exposes **CRUD APIs** to manage articles.

### Phase 2 â€“ Content Enrichment Pipeline

- Fetches articles via Phase-1 APIs.
- Searches article titles on Google.
- Scrapes ranking external articles.
- Uses an LLM to rewrite and enhance original content.
- Publishes updated articles via APIs.
- Stores reference links used for rewriting.

### Phase 3 â€“ Frontend UI

- React + TypeScript frontend.
- Displays original and updated articles.
- Responsive, clean, professional UI.

---

## ğŸ›  Tech Stack

### Backend

- Node.js
- Express
- MongoDB
- Axios
- Cheerio (scraping)
- Google Search API
- LLM API (Gemini)

### Frontend

- React (Vite)
- TypeScript
- React Router
- Axios
- CSS (custom, no UI library)

---

## ğŸ“ Project Structure

```txt
beyondchats-assessment/
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ .env
â”‚
â”œâ”€â”€ server/phase2/
â”‚   â”œâ”€â”€ googleSearch.js
â”‚   â”œâ”€â”€ contentScraper.js
â”‚   â”œâ”€â”€ llm.service.js
â”‚   â””â”€â”€ runPhase2.js
â”‚
â”œâ”€â”€ client/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ README.md
```

## ğŸ” Environment Variables Setup

Create a .env file inside the server/ directory and add the following variables:

```txt
PORT=8000

MONGO_URI=your_mongodb_connection_string

LLM_PROVIDER=gemini

GEMINI_API_KEY=your_gemini_api_key

GOOGLE_CX=your_google_custom_search_id

GOOGLE_API_KEY=your_google_api_key
```

## âš™ï¸ Backend Setup (Phase 1)

Navigate to the backend directory and install dependencies:

```txt
cd server
npm install
npm start
```

The backend will run on:

http://localhost:8000

This service:

- Scrapes articles from BeyondChats

- Stores them in MongoDB

- Exposes CRUD APIs for articles

## ğŸ¤– Phase 2 Automation Script Setup

- The Phase 2 script uses the same .env file inside server/.

- Run the automation script from the server/ directory:

```txt
node phase2/runPhase2.js
```

This script will:

- Fetch scraped articles via backend APIs

- Search article titles on Google

- Scrape external ranking articles

- Rewrite content using the configured LLM provider(Gemini)

- Update articles and store reference links

### Note: Some external websites may block scraping (403/500). In such cases, the system proceeds with available valid sources to avoid pipeline failure.

## ğŸ–¥ Frontend Setup (Phase 3)

Navigate to the frontend directory:

```txt
cd client
npm install
npm run dev
```

The frontend will be available at:

http://localhost:5173

## âš ï¸ Known Limitations

- Some websites may block scraping attempts (403/500 errors)
- Scraping success depends on target website structure and anti-bot measures

## ğŸ¤ Contribution

This is a assignment project, made by Akash
